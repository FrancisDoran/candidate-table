{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get stuff out of Netfile v2 API\n",
    "\"\"\"\n",
    "from pprint import PrettyPrinter\n",
    "from pathlib import Path\n",
    "import os\n",
    "import requests\n",
    "\n",
    "BASE_URL = 'https://netfile.com/api/campaign'\n",
    "CONTRIBUTION_FORM = 'F460A'\n",
    "EXPENDITURE_FORM = 'F460E'\n",
    "\n",
    "PARAMS = { 'aid': 'COAK' }\n",
    "\n",
    "def get_auth_from_env_file(filename: str='.env'):\n",
    "    \"\"\" Split .env file on newline and look for API_KEY and API_SECRET\n",
    "        Return their values as a tuple\n",
    "    \"\"\"\n",
    "    env_file=Path(filename)\n",
    "    auth_keys = [ 'API_KEY', 'API_SECRET' ]\n",
    "    if env_file.exists():\n",
    "        auth = tuple( v for _, v in sorted([\n",
    "            ln.split('=') for ln in\n",
    "            env_file.read_text(encoding='utf8').strip().split('\\n')\n",
    "            if ln.startswith(auth_keys[0]) or ln.startswith(auth_keys[1])\n",
    "        ], key=lambda ln: auth_keys.index(ln[0])))\n",
    "    else:\n",
    "        auth=tuple(os.environ[key] for key in auth_keys)\n",
    "            \n",
    "    return auth\n",
    "\n",
    "AUTH=get_auth_from_env_file()\n",
    "\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "def get_filing(offset=0):\n",
    "    \"\"\" Get a filing\n",
    "    \"\"\"\n",
    "    url = f'{BASE_URL}/filing/v101/filings'\n",
    "\n",
    "    params = { **PARAMS }\n",
    "    if offset > 0:\n",
    "        params['offset'] = offset\n",
    "\n",
    "    res = requests.get(url, params=params, auth=AUTH)\n",
    "    if res.status_code == 500:\n",
    "        print('ping')\n",
    "        return get_filing(offset=0)\n",
    "    else:\n",
    "        print(res)\n",
    "        body = res.json()\n",
    "        results = body.pop('results')\n",
    "        return results, body\n",
    "def get_form(form,offset=0):\n",
    "    \"\"\" Get a filing\n",
    "    \"\"\"\n",
    "    url = f'{BASE_URL}/filing/v101/filings?Limit=100000&SpecificationForm={form}'\n",
    "\n",
    "    params = { **PARAMS }\n",
    "    if offset > 0:\n",
    "        params['offset'] = offset\n",
    "\n",
    "    res = requests.get(url, params=params, auth=AUTH)\n",
    "    if res.status_code == 500:\n",
    "        return get_form(form,offset=0)\n",
    "    else:\n",
    "        body = res.json()\n",
    "        results = body.pop('results')\n",
    "\n",
    "        return results, body\n",
    "def get_filer(filer_nid):\n",
    "    \"\"\" Get one filer\n",
    "    \"\"\"\n",
    "    url = f'{BASE_URL}/filer/v101/filers?'\n",
    "\n",
    "    res = requests.get(url, params={ **PARAMS, 'filerNid': filer_nid }, auth=AUTH)\n",
    "    if res.status_code == 500:\n",
    "        return get_filer(filer_nid)\n",
    "    else:\n",
    "        body = res.json()\n",
    "\n",
    "        return body['results']\n",
    "def list_filers():\n",
    "    \"\"\" Get all the elections\n",
    "    \"\"\"\n",
    "    url = f'{BASE_URL}/filer/v101/filers?Limit=100000'\n",
    "\n",
    "    res = requests.get(url, params=PARAMS, auth=AUTH)\n",
    "    if res.status_code == 500:\n",
    "        print('ping')\n",
    "        return list_filers()\n",
    "    else:\n",
    "        body = res.json()\n",
    "        return body['results']\n",
    "def list_elections_influences(id):\n",
    "    \"\"\" Get all the elections\n",
    "    \"\"\"\n",
    "    url = f'{BASE_URL}/election/v101/election-influences?Limit=100000&ElectionNid={id}'\n",
    "\n",
    "    res = requests.get(url, params=PARAMS, auth=AUTH)\n",
    "    if res.status_code == 500:\n",
    "        return list_elections_influences(id)\n",
    "    else:\n",
    "        body = res.json()\n",
    "        return body['results']\n",
    "\n",
    "def list_elections():\n",
    "    \"\"\" Get all the elections\n",
    "    \"\"\"\n",
    "    url = f'{BASE_URL}/election/v101/elections?Limit=100000'\n",
    "\n",
    "    res = requests.get(url, params=PARAMS, auth=AUTH)\n",
    "    if res.status_code == 500:\n",
    "        return list_elections()\n",
    "    else:\n",
    "        body = res.json()\n",
    "\n",
    "        return body['results']\n",
    "def export_transactions(id,offset=0):\n",
    "    \"\"\" Get a filing\n",
    "    \"\"\"\n",
    "    url = f'{BASE_URL}/filing/v101/filings/{id}'\n",
    "\n",
    "    params = { **PARAMS }\n",
    "    if offset > 0:\n",
    "        params['offset'] = offset\n",
    "\n",
    "    res = requests.get(url, params=params, auth=AUTH)\n",
    "    if res.status_code == 500:\n",
    "        return export_transactions(id,offset=0)\n",
    "    else:\n",
    "        body = res.json()\n",
    "\n",
    "        return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filers_response=list_filers()\n",
    "filers_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = [\n",
    "    {\n",
    "        'isTerminated': item.get('isTerminated', {}),\n",
    "        # Get the latest status and conditons for epmty lists to avoid indexError\n",
    "        'status': item.get('statusItemList', None)[-1]['status'] if item.get('statusItemList', None) else None,\n",
    "        'filerNid': item['filerNid'],\n",
    "        'Filer Name':item['filerName'],\n",
    "        'Filer Type': item['committeeTypes']\n",
    "    } \n",
    "    for item in filers_response\n",
    "]\n",
    "status_df = pd.DataFrame(status)\n",
    "# status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get city, state, and zip from Disclosure addresses\n",
    "addresses=[{'addressList':item.get('addressList',{}),'filerNid':item['filerNid']} for item in filers_response]\n",
    "address_dic = {'city':[],'state':[],'zip':[],'filerNid':[]}\n",
    "for item in addresses:\n",
    "    for address in item['addressList']:\n",
    "        if 'Disclosure' in address['addressTypes']:\n",
    "            address_dic['city'].append(address['city'])\n",
    "            address_dic['state'].append(address['state'])\n",
    "            address_dic['zip'].append(address['zip'])\n",
    "            address_dic['filerNid'].append(item['filerNid'])\n",
    "address_df=pd.DataFrame(address_dic)\n",
    "# address_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on filer id\n",
    "status_address_df = status_df.merge(address_df,how='left', on='filerNid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate a filer id to a fppc id\n",
    "regs=[{'fppc_id':item.get('registrations',{}).get('CA SOS',None),'filerNid':item['filerNid']} for item in filers_response]\n",
    "# get all filers with officers\n",
    "officers=[[item['officers'], item['filerNid']] for item in filers_response if item['officers']]\n",
    "# set up dictionary\n",
    "treasurer_dic={}\n",
    "# loop through filers with officers and add offcier names if officer position is treasurer the key will be the filler id\n",
    "for officer in officers:\n",
    "    if officer[0][0]['position']=='Treasurer':\n",
    "        treasurer_dic[officer[1]]=officer[0][0]['officerName']\n",
    "# match the filer id key in treasurer dic with the filer ids associated with an fppc id\n",
    "for key, value in treasurer_dic.items():\n",
    "    for item in regs:\n",
    "        if key==item['filerNid']:\n",
    "            # if a key matches a filer id then add treasure name to the dictionaries\n",
    "            item['Treasurer']=value\n",
    "# get only the cases with a treasurer\n",
    "fppc_with_treasurer=[reg for reg in regs if reg.get('Treasurer', None)]\n",
    "treasurer_df=pd.DataFrame(fppc_with_treasurer)\n",
    "# treasurer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to associate fppc ids with filer nids, I look through 410s, 501s, and filers_response.\n",
    "# get ids from 410s\n",
    "form410s=get_form('FPPC410')\n",
    "form410s=form410s[0]\n",
    "form410={'filerNid':[],'fppc_id':[]}\n",
    "for form in form410s:\n",
    "    form410['filerNid'].append(form['filerMeta']['filerId'])\n",
    "    form410['fppc_id'].append(form.get('filerMeta',{}).get('strings',{}).get('Registration_CA SOS',None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids from 501s\n",
    "form501s=get_form('FPPC501')\n",
    "form501s=form501s[0]\n",
    "for form in form501s:\n",
    "    form410['filerNid'].append(form['filerMeta']['filerId'])\n",
    "    form410['fppc_id'].append(form.get('filerMeta',{}).get('strings',{}).get('Registration_CA SOS',None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids from filer_response\n",
    "for item in filers_response:\n",
    "    form410['filerNid'].append(item.get('filerNid',{}))\n",
    "    form410['fppc_id'].append(item.get('registrations',{}).get('CA SOS',None))\n",
    "df_410=pd.DataFrame(form410)\n",
    "df_410.drop_duplicates(inplace=True)\n",
    "# In this data filer id can be associated with an ffpc id, a null value, or 'pending', I filter it for the best results then concatenate the best results last\n",
    "# then drop duplicates keeping last since I put the prefferable rows last\n",
    "# drop null values\n",
    "t2=df_410.dropna()\n",
    "# drop pending, this now only has preferable rows\n",
    "t1=t2[t2['fppc_id'] != 'Pending']\n",
    "duped=pd.concat([df_410, t2, t1], ignore_index=True)\n",
    "best=duped.drop_duplicates(subset=['filerNid'],keep='last',inplace=False)\n",
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all elections\n",
    "elections=list_elections()\n",
    "# elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the list_elections response we ... \n",
    "election_list=[]\n",
    "previous_df=pd.DataFrame()\n",
    "for election in elections:\n",
    "    # collect \n",
    "    candidates=election['candidates']\n",
    "    seats=election['seats']\n",
    "    election_name=election['electionCaption']\n",
    "    electionNid=election['electionNid']\n",
    "    # get the year from the four first character, the format is yyyy-mm-dd\n",
    "    election_year=election['electionDate'][:4]\n",
    "    election_key={'election_name':election_name, 'electionNid':electionNid, 'election year':election_year}\n",
    "    election_list.append(election_key)\n",
    "    if candidates and seats:\n",
    "        seat_df=pd.DataFrame(seats)\n",
    "        candidate_df=pd.DataFrame(candidates)\n",
    "        merge_df=candidate_df.merge(seat_df, on='seatNid')\n",
    "        current_df=merge_df[['candidateNid','candidateName','seatNid','officeName','electionNid','isIncumbent','isWinner']]\n",
    "        previous_df=pd.concat([previous_df,current_df],ignore_index=True)\n",
    "election_df=pd.DataFrame(election_list)\n",
    "final_df=previous_df.merge(election_df, on='electionNid')\n",
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_ids=list(set(final_df['electionNid'].to_list()))\n",
    "previous_df=pd.DataFrame()\n",
    "for id in election_ids:\n",
    "    influences=list_elections_influences(id)\n",
    "    influences_dic={'filerNid': [],'electionNid': [],'seatNid': [],'candidateNid': [],'committeeName':[],'election_name': []}\n",
    "    for candidate in influences:   \n",
    "        influences_dic['filerNid'].append(candidate.get('filerNid', 'None'))\n",
    "        influences_dic['election_name'].append(candidate.get('electionCaption', 'None'))\n",
    "        influences_dic['committeeName'].append(candidate.get('committeeName', 'None'))\n",
    "        influences_dic['electionNid'].append(candidate.get('electionNid', 'None'))\n",
    "        influences_dic['seatNid'].append(candidate.get('seatNid', 'None'))\n",
    "        influences_dic['candidateNid'].append(candidate.get('candidateNid', 'None'))\n",
    "        current_df=pd.DataFrame(influences_dic)\n",
    "        current_df=current_df\n",
    "        previous_df=pd.concat([previous_df,current_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=previous_df\n",
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew = final_df.merge(df3,how='left', on=['candidateNid','election_name','electionNid','seatNid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_df=dfNew[['candidateName','officeName','committeeName','election_name','filerNid','election year']] \n",
    "df4=core_df.merge(best, how='left',on=['filerNid']).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge treasurer with fppc id and filer id as keys\n",
    "df5 = df4.merge(treasurer_df, how='left',on=['fppc_id','filerNid'])\n",
    "# merge status and location with filer id as key\n",
    "df6 = df5.merge(status_address_df, how='left',on=['filerNid'])\n",
    "# rename columns for consistent style\n",
    "df6.columns = ['Candidate Name','Office Name', 'Committee Name', 'Election Name', 'Filler Nid', 'Election Year', 'FPPC ID', 'Treasurer', 'Is Terminated', 'Status', 'Filer Name', 'Filer Type', 'City', 'State', 'Zip']\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output table as csv\n",
    "df6.to_csv('output/output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
